{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "frog = pd.read_csv('frogs_mfcc.csv', sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "# specify feature names & target names\n",
    "x=frog[[\"MFCCs_ 1\",\"MFCCs_ 2\",\"MFCCs_ 3\",\"MFCCs_ 4\",\"MFCCs_ 5\",\"MFCCs_ 6\",\"MFCCs_ 7\",\"MFCCs_ 8\",\"MFCCs_ 9\",\"MFCCs_10\",\n",
    "        \"MFCCs_11\",\"MFCCs_12\",\"MFCCs_13\",\"MFCCs_14\",\"MFCCs_15\",\"MFCCs_16\",\"MFCCs_17\",\"MFCCs_18\",\"MFCCs_19\",\n",
    "        \"MFCCs_20\",\"MFCCs_21\",\"MFCCs_22\"]]\n",
    "y=frog[[\"Species\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower limit calculated are: \n",
      " MFCCs_ 1    1.000000\n",
      "MFCCs_ 2   -0.284987\n",
      "MFCCs_ 3   -0.299929\n",
      "MFCCs_ 4    0.002050\n",
      "MFCCs_ 5   -0.204594\n",
      "MFCCs_ 6   -0.232482\n",
      "MFCCs_ 7   -0.442713\n",
      "MFCCs_ 8   -0.270433\n",
      "MFCCs_ 9   -0.386471\n",
      "MFCCs_10   -0.179418\n",
      "MFCCs_11   -0.714684\n",
      "MFCCs_12   -0.283475\n",
      "MFCCs_13   -0.494030\n",
      "MFCCs_14   -0.391186\n",
      "MFCCs_15   -0.665846\n",
      "MFCCs_16   -0.209441\n",
      "MFCCs_17   -0.307307\n",
      "MFCCs_18   -0.198139\n",
      "MFCCs_19   -0.274680\n",
      "MFCCs_20   -0.304439\n",
      "MFCCs_21   -0.178478\n",
      "MFCCs_22   -0.290896\n",
      "dtype: float64\n",
      "Upper limit calculated are: \n",
      " MFCCs_ 1    1.000000\n",
      "MFCCs_ 2    0.917498\n",
      "MFCCs_ 3    0.869069\n",
      "MFCCs_ 4    0.894548\n",
      "MFCCs_ 5    0.478903\n",
      "MFCCs_ 6    0.421020\n",
      "MFCCs_ 7    0.402555\n",
      "MFCCs_ 8    0.282432\n",
      "MFCCs_ 9    0.656514\n",
      "MFCCs_10    0.296011\n",
      "MFCCs_11    0.471513\n",
      "MFCCs_12    0.381976\n",
      "MFCCs_13    0.815760\n",
      "MFCCs_14    0.297364\n",
      "MFCCs_15    0.427265\n",
      "MFCCs_16    0.296938\n",
      "MFCCs_17    0.507475\n",
      "MFCCs_18    0.217905\n",
      "MFCCs_19    0.174921\n",
      "MFCCs_20    0.184810\n",
      "MFCCs_21    0.250477\n",
      "MFCCs_22    0.486248\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def interQuartile(x):\n",
    "  percentile25= x.quantile(0.25)\n",
    "  percentile75=x.quantile(0.75)\n",
    "  iqr=percentile75-percentile25\n",
    "  upperLimit= percentile75+1.5*iqr\n",
    "  lowerLimit= percentile25-1.5*iqr\n",
    "  return upperLimit, lowerLimit\n",
    "\n",
    "upper,lower= interQuartile(x)\n",
    "print(\"Lower limit calculated are: \\n\", lower)\n",
    "print(\"Upper limit calculated are: \\n\", upper)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries below the lower limit are \n",
      " MFCCs_ 1    248\n",
      "MFCCs_ 2     40\n",
      "MFCCs_ 3     19\n",
      "MFCCs_ 4    106\n",
      "MFCCs_ 5    364\n",
      "MFCCs_ 6      4\n",
      "MFCCs_ 7      2\n",
      "MFCCs_ 8    127\n",
      "MFCCs_ 9     17\n",
      "MFCCs_10    372\n",
      "MFCCs_11      3\n",
      "MFCCs_12    177\n",
      "MFCCs_13     17\n",
      "MFCCs_14     22\n",
      "MFCCs_15      1\n",
      "MFCCs_16    142\n",
      "MFCCs_17     16\n",
      "MFCCs_18     91\n",
      "MFCCs_19     13\n",
      "MFCCs_20      7\n",
      "MFCCs_21     29\n",
      "MFCCs_22      6\n",
      "dtype: int64\n",
      "Number of entries above the upper limit are \n",
      " MFCCs_ 1      0\n",
      "MFCCs_ 2     95\n",
      "MFCCs_ 3    306\n",
      "MFCCs_ 4     33\n",
      "MFCCs_ 5     59\n",
      "MFCCs_ 6     82\n",
      "MFCCs_ 7    331\n",
      "MFCCs_ 8     39\n",
      "MFCCs_ 9      1\n",
      "MFCCs_10    222\n",
      "MFCCs_11      6\n",
      "MFCCs_12    181\n",
      "MFCCs_13      2\n",
      "MFCCs_14    148\n",
      "MFCCs_15     28\n",
      "MFCCs_16    164\n",
      "MFCCs_17      1\n",
      "MFCCs_18     39\n",
      "MFCCs_19     49\n",
      "MFCCs_20     76\n",
      "MFCCs_21     30\n",
      "MFCCs_22      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of entries below the lower limit are \\n\", (x < lower).sum())\n",
    "print(\"Number of entries above the upper limit are \\n\", (x > upper).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4317, 22)\n",
      "(1439, 22)\n",
      "(1439, 22)\n",
      "(1439, 1)\n",
      "(4317, 1)\n",
      "(1439, 1)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the training, test & validation set to 80:10:10 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# importing the class\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "logreg = SGDClassifier(loss='log', eta0=0.01, learning_rate='constant', penalty=None, max_iter=200, random_state=100, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2.51, NNZs: 22, Bias: -0.956496, T: 4317, Avg. loss: 0.238322\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.70, NNZs: 22, Bias: -0.984429, T: 8634, Avg. loss: 0.160666\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.58, NNZs: 22, Bias: -1.162139, T: 12951, Avg. loss: 0.133215\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5.26, NNZs: 22, Bias: -1.220887, T: 17268, Avg. loss: 0.117728\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.81, NNZs: 22, Bias: -1.297874, T: 21585, Avg. loss: 0.108086\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6.29, NNZs: 22, Bias: -1.397362, T: 25902, Avg. loss: 0.101277\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.69, NNZs: 22, Bias: -1.494238, T: 30219, Avg. loss: 0.095998\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.06, NNZs: 22, Bias: -1.507157, T: 34536, Avg. loss: 0.091940\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.38, NNZs: 22, Bias: -1.642130, T: 38853, Avg. loss: 0.088615\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.69, NNZs: 22, Bias: -1.642155, T: 43170, Avg. loss: 0.085968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.96, NNZs: 22, Bias: -1.724655, T: 47487, Avg. loss: 0.083603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 8.22, NNZs: 22, Bias: -1.726664, T: 51804, Avg. loss: 0.081632\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 8.46, NNZs: 22, Bias: -1.823998, T: 56121, Avg. loss: 0.079671\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.69, NNZs: 22, Bias: -1.837542, T: 60438, Avg. loss: 0.078180\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.90, NNZs: 22, Bias: -1.848445, T: 64755, Avg. loss: 0.076868\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 9.10, NNZs: 22, Bias: -1.900696, T: 69072, Avg. loss: 0.075582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 9.29, NNZs: 22, Bias: -1.948720, T: 73389, Avg. loss: 0.074402\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 9.47, NNZs: 22, Bias: -1.935112, T: 77706, Avg. loss: 0.073414\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 9.64, NNZs: 22, Bias: -2.003071, T: 82023, Avg. loss: 0.072462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 9.82, NNZs: 22, Bias: -1.971241, T: 86340, Avg. loss: 0.071344\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9.97, NNZs: 22, Bias: -2.045733, T: 90657, Avg. loss: 0.070791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.13, NNZs: 22, Bias: -2.048238, T: 94974, Avg. loss: 0.069955\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.28, NNZs: 22, Bias: -2.057737, T: 99291, Avg. loss: 0.069155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.43, NNZs: 22, Bias: -2.094844, T: 103608, Avg. loss: 0.068595\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.57, NNZs: 22, Bias: -2.114491, T: 107925, Avg. loss: 0.067918\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 25 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4.25, NNZs: 22, Bias: -0.594259, T: 4317, Avg. loss: 0.342700\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.91, NNZs: 22, Bias: -0.849852, T: 8634, Avg. loss: 0.158834\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6.96, NNZs: 22, Bias: -1.073086, T: 12951, Avg. loss: 0.115524\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.73, NNZs: 22, Bias: -1.224103, T: 17268, Avg. loss: 0.095185\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.35, NNZs: 22, Bias: -1.300647, T: 21585, Avg. loss: 0.083322\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.86, NNZs: 22, Bias: -1.390488, T: 25902, Avg. loss: 0.075395\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.30, NNZs: 22, Bias: -1.473914, T: 30219, Avg. loss: 0.069669\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 9.69, NNZs: 22, Bias: -1.519581, T: 34536, Avg. loss: 0.065312\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 10.02, NNZs: 22, Bias: -1.629067, T: 38853, Avg. loss: 0.061833\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 10.33, NNZs: 22, Bias: -1.680165, T: 43170, Avg. loss: 0.059063\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 10.62, NNZs: 22, Bias: -1.696304, T: 47487, Avg. loss: 0.056770\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 10.87, NNZs: 22, Bias: -1.767252, T: 51804, Avg. loss: 0.054751\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.12, NNZs: 22, Bias: -1.775606, T: 56121, Avg. loss: 0.053085\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.35, NNZs: 22, Bias: -1.793183, T: 60438, Avg. loss: 0.051600\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.56, NNZs: 22, Bias: -1.812178, T: 64755, Avg. loss: 0.050277\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.76, NNZs: 22, Bias: -1.854592, T: 69072, Avg. loss: 0.049165\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.95, NNZs: 22, Bias: -1.880315, T: 73389, Avg. loss: 0.048103\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 12.13, NNZs: 22, Bias: -1.899601, T: 77706, Avg. loss: 0.047163\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 12.30, NNZs: 22, Bias: -1.917522, T: 82023, Avg. loss: 0.046304\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 12.46, NNZs: 22, Bias: -1.931138, T: 86340, Avg. loss: 0.045544\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 12.62, NNZs: 22, Bias: -1.948751, T: 90657, Avg. loss: 0.044835\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 12.77, NNZs: 22, Bias: -1.965434, T: 94974, Avg. loss: 0.044183\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.26, NNZs: 22, Bias: -0.887403, T: 4317, Avg. loss: 0.232532\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.18, NNZs: 22, Bias: -0.729238, T: 8634, Avg. loss: 0.176608\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.90, NNZs: 22, Bias: -0.704033, T: 12951, Avg. loss: 0.156597\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.48, NNZs: 22, Bias: -0.693135, T: 17268, Avg. loss: 0.144889\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.97, NNZs: 22, Bias: -0.734320, T: 21585, Avg. loss: 0.136715\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.40, NNZs: 22, Bias: -0.738966, T: 25902, Avg. loss: 0.130572\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5.78, NNZs: 22, Bias: -0.709630, T: 30219, Avg. loss: 0.125289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 6.14, NNZs: 22, Bias: -0.799153, T: 34536, Avg. loss: 0.120775\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 6.47, NNZs: 22, Bias: -0.696230, T: 38853, Avg. loss: 0.116765\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 6.79, NNZs: 22, Bias: -0.781228, T: 43170, Avg. loss: 0.113631\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.09, NNZs: 22, Bias: -0.778951, T: 47487, Avg. loss: 0.110580\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 7.38, NNZs: 22, Bias: -0.802567, T: 51804, Avg. loss: 0.107764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 7.66, NNZs: 22, Bias: -0.764553, T: 56121, Avg. loss: 0.105304\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 7.92, NNZs: 22, Bias: -0.804963, T: 60438, Avg. loss: 0.103141\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.18, NNZs: 22, Bias: -0.855551, T: 64755, Avg. loss: 0.100955\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.42, NNZs: 22, Bias: -0.820051, T: 69072, Avg. loss: 0.099155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8.66, NNZs: 22, Bias: -0.841672, T: 73389, Avg. loss: 0.097468\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8.89, NNZs: 22, Bias: -0.865370, T: 77706, Avg. loss: 0.095846\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 9.11, NNZs: 22, Bias: -0.858504, T: 82023, Avg. loss: 0.094345\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 9.33, NNZs: 22, Bias: -0.881381, T: 86340, Avg. loss: 0.092982\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9.53, NNZs: 22, Bias: -0.849910, T: 90657, Avg. loss: 0.091634\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 9.73, NNZs: 22, Bias: -0.892973, T: 94974, Avg. loss: 0.090565\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 9.93, NNZs: 22, Bias: -0.903217, T: 99291, Avg. loss: 0.089468\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.12, NNZs: 22, Bias: -0.922954, T: 103608, Avg. loss: 0.088343\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.30, NNZs: 22, Bias: -0.966944, T: 107925, Avg. loss: 0.087354\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.48, NNZs: 22, Bias: -0.919733, T: 112242, Avg. loss: 0.086517\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.65, NNZs: 22, Bias: -0.938577, T: 116559, Avg. loss: 0.085540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 10.82, NNZs: 22, Bias: -0.940164, T: 120876, Avg. loss: 0.084807\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10.99, NNZs: 22, Bias: -0.940455, T: 125193, Avg. loss: 0.084036\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 29 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.84, NNZs: 22, Bias: -1.203174, T: 4317, Avg. loss: 0.185708\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.27, NNZs: 22, Bias: -1.147443, T: 8634, Avg. loss: 0.155970\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.70, NNZs: 22, Bias: -1.129910, T: 12951, Avg. loss: 0.147115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.10, NNZs: 22, Bias: -1.118421, T: 17268, Avg. loss: 0.140841\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.47, NNZs: 22, Bias: -1.148580, T: 21585, Avg. loss: 0.136158\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.80, NNZs: 22, Bias: -1.181123, T: 25902, Avg. loss: 0.132448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.10, NNZs: 22, Bias: -1.235659, T: 30219, Avg. loss: 0.129218\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.36, NNZs: 22, Bias: -1.215886, T: 34536, Avg. loss: 0.126735\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.61, NNZs: 22, Bias: -1.212431, T: 38853, Avg. loss: 0.124747\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.85, NNZs: 22, Bias: -1.227451, T: 43170, Avg. loss: 0.122774\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5.08, NNZs: 22, Bias: -1.223535, T: 47487, Avg. loss: 0.121058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 5.30, NNZs: 22, Bias: -1.299339, T: 51804, Avg. loss: 0.119416\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 5.49, NNZs: 22, Bias: -1.256428, T: 56121, Avg. loss: 0.118070\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 5.69, NNZs: 22, Bias: -1.279979, T: 60438, Avg. loss: 0.116829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 5.87, NNZs: 22, Bias: -1.282525, T: 64755, Avg. loss: 0.115775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 6.05, NNZs: 22, Bias: -1.306414, T: 69072, Avg. loss: 0.114716\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 6.22, NNZs: 22, Bias: -1.255265, T: 73389, Avg. loss: 0.113575\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 6.39, NNZs: 22, Bias: -1.315901, T: 77706, Avg. loss: 0.112732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 6.55, NNZs: 22, Bias: -1.306201, T: 82023, Avg. loss: 0.111957\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 6.71, NNZs: 22, Bias: -1.359112, T: 86340, Avg. loss: 0.111290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 6.86, NNZs: 22, Bias: -1.353645, T: 90657, Avg. loss: 0.110500\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 7.00, NNZs: 22, Bias: -1.346856, T: 94974, Avg. loss: 0.109811\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.37, NNZs: 22, Bias: -1.226207, T: 4317, Avg. loss: 0.201559\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.55, NNZs: 22, Bias: -1.473266, T: 8634, Avg. loss: 0.122911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.38, NNZs: 22, Bias: -1.678361, T: 12951, Avg. loss: 0.095211\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.99, NNZs: 22, Bias: -1.920748, T: 17268, Avg. loss: 0.081093\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.48, NNZs: 22, Bias: -2.029624, T: 21585, Avg. loss: 0.072961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.88, NNZs: 22, Bias: -2.153219, T: 25902, Avg. loss: 0.067401\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.22, NNZs: 22, Bias: -2.287884, T: 30219, Avg. loss: 0.063559\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 6.51, NNZs: 22, Bias: -2.380025, T: 34536, Avg. loss: 0.060667\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 6.76, NNZs: 22, Bias: -2.507185, T: 38853, Avg. loss: 0.058347\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.00, NNZs: 22, Bias: -2.530803, T: 43170, Avg. loss: 0.056505\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.20, NNZs: 22, Bias: -2.678968, T: 47487, Avg. loss: 0.054907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 7.40, NNZs: 22, Bias: -2.711244, T: 51804, Avg. loss: 0.053710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 7.57, NNZs: 22, Bias: -2.793947, T: 56121, Avg. loss: 0.052613\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 7.73, NNZs: 22, Bias: -2.862847, T: 60438, Avg. loss: 0.051624\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 7.87, NNZs: 22, Bias: -2.949745, T: 64755, Avg. loss: 0.050787\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.02, NNZs: 22, Bias: -3.003751, T: 69072, Avg. loss: 0.049991\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8.15, NNZs: 22, Bias: -3.053725, T: 73389, Avg. loss: 0.049269\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8.27, NNZs: 22, Bias: -3.138745, T: 77706, Avg. loss: 0.048696\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 18 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.85, NNZs: 22, Bias: -0.672789, T: 4317, Avg. loss: 0.396517\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.86, NNZs: 22, Bias: -0.680957, T: 8634, Avg. loss: 0.349501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.71, NNZs: 22, Bias: -0.683878, T: 12951, Avg. loss: 0.324740\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.46, NNZs: 22, Bias: -0.668709, T: 17268, Avg. loss: 0.306913\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.14, NNZs: 22, Bias: -0.652064, T: 21585, Avg. loss: 0.292753\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.77, NNZs: 22, Bias: -0.707517, T: 25902, Avg. loss: 0.281065\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.34, NNZs: 22, Bias: -0.757788, T: 30219, Avg. loss: 0.271693\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 6.86, NNZs: 22, Bias: -0.656206, T: 34536, Avg. loss: 0.263765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.35, NNZs: 22, Bias: -0.691497, T: 38853, Avg. loss: 0.256783\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.81, NNZs: 22, Bias: -0.742835, T: 43170, Avg. loss: 0.250673\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 8.25, NNZs: 22, Bias: -0.770619, T: 47487, Avg. loss: 0.245223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 8.66, NNZs: 22, Bias: -0.817298, T: 51804, Avg. loss: 0.240360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 9.05, NNZs: 22, Bias: -0.774070, T: 56121, Avg. loss: 0.236195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 9.42, NNZs: 22, Bias: -0.831869, T: 60438, Avg. loss: 0.232381\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 9.78, NNZs: 22, Bias: -0.833941, T: 64755, Avg. loss: 0.228732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 10.12, NNZs: 22, Bias: -0.943353, T: 69072, Avg. loss: 0.225276\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 10.44, NNZs: 22, Bias: -0.910820, T: 73389, Avg. loss: 0.222433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 10.76, NNZs: 22, Bias: -0.895794, T: 77706, Avg. loss: 0.219665\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 11.06, NNZs: 22, Bias: -0.923530, T: 82023, Avg. loss: 0.217093\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 11.35, NNZs: 22, Bias: -0.890665, T: 86340, Avg. loss: 0.214642\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.64, NNZs: 22, Bias: -0.977381, T: 90657, Avg. loss: 0.212399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 11.91, NNZs: 22, Bias: -1.039368, T: 94974, Avg. loss: 0.209831\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 12.17, NNZs: 22, Bias: -0.948323, T: 99291, Avg. loss: 0.208285\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12.43, NNZs: 22, Bias: -1.030837, T: 103608, Avg. loss: 0.206542\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12.68, NNZs: 22, Bias: -1.071671, T: 107925, Avg. loss: 0.204564\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 12.92, NNZs: 22, Bias: -1.015914, T: 112242, Avg. loss: 0.202733\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 13.15, NNZs: 22, Bias: -1.046721, T: 116559, Avg. loss: 0.201244\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 13.38, NNZs: 22, Bias: -1.065511, T: 120876, Avg. loss: 0.200095\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 13.61, NNZs: 22, Bias: -1.106630, T: 125193, Avg. loss: 0.198765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 13.82, NNZs: 22, Bias: -1.127656, T: 129510, Avg. loss: 0.197280\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 14.04, NNZs: 22, Bias: -1.210040, T: 133827, Avg. loss: 0.196068\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 14.24, NNZs: 22, Bias: -1.179918, T: 138144, Avg. loss: 0.194798\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 14.45, NNZs: 22, Bias: -1.209037, T: 142461, Avg. loss: 0.193621\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 14.64, NNZs: 22, Bias: -1.220071, T: 146778, Avg. loss: 0.192579\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14.84, NNZs: 22, Bias: -1.254418, T: 151095, Avg. loss: 0.191384\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 15.03, NNZs: 22, Bias: -1.198962, T: 155412, Avg. loss: 0.190345\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 15.21, NNZs: 22, Bias: -1.242972, T: 159729, Avg. loss: 0.189468\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 15.39, NNZs: 22, Bias: -1.313984, T: 164046, Avg. loss: 0.188345\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 15.57, NNZs: 22, Bias: -1.306980, T: 168363, Avg. loss: 0.187638\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 15.75, NNZs: 22, Bias: -1.280788, T: 172680, Avg. loss: 0.186442\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 15.92, NNZs: 22, Bias: -1.341316, T: 176997, Avg. loss: 0.185917\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 16.08, NNZs: 22, Bias: -1.383459, T: 181314, Avg. loss: 0.184669\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 16.25, NNZs: 22, Bias: -1.382838, T: 185631, Avg. loss: 0.184131\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 16.41, NNZs: 22, Bias: -1.416650, T: 189948, Avg. loss: 0.183106\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 16.57, NNZs: 22, Bias: -1.436390, T: 194265, Avg. loss: 0.182785\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 16.73, NNZs: 22, Bias: -1.460338, T: 198582, Avg. loss: 0.181865\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 16.88, NNZs: 22, Bias: -1.430850, T: 202899, Avg. loss: 0.181208\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 17.03, NNZs: 22, Bias: -1.475113, T: 207216, Avg. loss: 0.180759\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 17.18, NNZs: 22, Bias: -1.445050, T: 211533, Avg. loss: 0.179894\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 49 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.91, NNZs: 22, Bias: -1.329936, T: 4317, Avg. loss: 0.173865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.59, NNZs: 22, Bias: -1.384021, T: 8634, Avg. loss: 0.131097\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.29, NNZs: 22, Bias: -1.445833, T: 12951, Avg. loss: 0.112047\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.97, NNZs: 22, Bias: -1.624868, T: 17268, Avg. loss: 0.097651\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.53, NNZs: 22, Bias: -1.619428, T: 21585, Avg. loss: 0.087418\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.04, NNZs: 22, Bias: -1.711713, T: 25902, Avg. loss: 0.079196\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5.50, NNZs: 22, Bias: -1.806014, T: 30219, Avg. loss: 0.072844\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.91, NNZs: 22, Bias: -1.861707, T: 34536, Avg. loss: 0.067544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 6.29, NNZs: 22, Bias: -1.945177, T: 38853, Avg. loss: 0.063329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 6.64, NNZs: 22, Bias: -2.002547, T: 43170, Avg. loss: 0.059728\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 6.96, NNZs: 22, Bias: -2.065317, T: 47487, Avg. loss: 0.056616\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 7.25, NNZs: 22, Bias: -2.138068, T: 51804, Avg. loss: 0.054120\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 7.53, NNZs: 22, Bias: -2.225235, T: 56121, Avg. loss: 0.051886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 7.78, NNZs: 22, Bias: -2.226686, T: 60438, Avg. loss: 0.049879\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.02, NNZs: 22, Bias: -2.308298, T: 64755, Avg. loss: 0.048298\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.25, NNZs: 22, Bias: -2.336698, T: 69072, Avg. loss: 0.046729\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8.46, NNZs: 22, Bias: -2.414143, T: 73389, Avg. loss: 0.045443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8.67, NNZs: 22, Bias: -2.447256, T: 77706, Avg. loss: 0.044205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8.86, NNZs: 22, Bias: -2.528769, T: 82023, Avg. loss: 0.043121\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 9.04, NNZs: 22, Bias: -2.564213, T: 86340, Avg. loss: 0.042180\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9.21, NNZs: 22, Bias: -2.611583, T: 90657, Avg. loss: 0.041289\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 9.38, NNZs: 22, Bias: -2.654848, T: 94974, Avg. loss: 0.040467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 9.54, NNZs: 22, Bias: -2.669028, T: 99291, Avg. loss: 0.039717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 9.69, NNZs: 22, Bias: -2.735210, T: 103608, Avg. loss: 0.039050\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 24 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.95, NNZs: 22, Bias: -1.590049, T: 4317, Avg. loss: 0.104896\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.14, NNZs: 22, Bias: -1.670247, T: 8634, Avg. loss: 0.074355\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.35, NNZs: 22, Bias: -1.740281, T: 12951, Avg. loss: 0.070804\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.54, NNZs: 22, Bias: -1.775381, T: 17268, Avg. loss: 0.068119\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.72, NNZs: 22, Bias: -1.801576, T: 21585, Avg. loss: 0.065971\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.91, NNZs: 22, Bias: -1.842964, T: 25902, Avg. loss: 0.064250\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 3.09, NNZs: 22, Bias: -1.883941, T: 30219, Avg. loss: 0.062834\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 3.26, NNZs: 22, Bias: -1.935026, T: 34536, Avg. loss: 0.061646\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 3.42, NNZs: 22, Bias: -1.963363, T: 38853, Avg. loss: 0.060649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 3.56, NNZs: 22, Bias: -1.996505, T: 43170, Avg. loss: 0.059808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 3.71, NNZs: 22, Bias: -2.046375, T: 47487, Avg. loss: 0.059078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 3.84, NNZs: 22, Bias: -2.093690, T: 51804, Avg. loss: 0.058378\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 3.96, NNZs: 22, Bias: -2.116599, T: 56121, Avg. loss: 0.057794\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 13 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.08, NNZs: 22, Bias: -1.689863, T: 4317, Avg. loss: 0.081380\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.30, NNZs: 22, Bias: -1.835614, T: 8634, Avg. loss: 0.049592\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.40, NNZs: 22, Bias: -1.871787, T: 12951, Avg. loss: 0.048489\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.48, NNZs: 22, Bias: -1.877758, T: 17268, Avg. loss: 0.047919\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.52, NNZs: 22, Bias: -1.856759, T: 21585, Avg. loss: 0.047435\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.59, NNZs: 22, Bias: -1.851017, T: 25902, Avg. loss: 0.047008\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.65, NNZs: 22, Bias: -1.835770, T: 30219, Avg. loss: 0.046611\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2.71, NNZs: 22, Bias: -1.820353, T: 34536, Avg. loss: 0.046253\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 8 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.96, NNZs: 22, Bias: -1.493546, T: 4317, Avg. loss: 0.123151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.14, NNZs: 22, Bias: -1.463816, T: 8634, Avg. loss: 0.095274\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.38, NNZs: 22, Bias: -1.445510, T: 12951, Avg. loss: 0.091384\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.64, NNZs: 22, Bias: -1.405838, T: 17268, Avg. loss: 0.087743\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.89, NNZs: 22, Bias: -1.335127, T: 21585, Avg. loss: 0.084253\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3.20, NNZs: 22, Bias: -1.319281, T: 25902, Avg. loss: 0.081015\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 3.50, NNZs: 22, Bias: -1.294317, T: 30219, Avg. loss: 0.077936\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 3.79, NNZs: 22, Bias: -1.247574, T: 34536, Avg. loss: 0.075041\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.08, NNZs: 22, Bias: -1.218902, T: 38853, Avg. loss: 0.072328\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.40, NNZs: 22, Bias: -1.235176, T: 43170, Avg. loss: 0.069696\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.69, NNZs: 22, Bias: -1.222907, T: 47487, Avg. loss: 0.067339\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.97, NNZs: 22, Bias: -1.211200, T: 51804, Avg. loss: 0.065125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 5.22, NNZs: 22, Bias: -1.127384, T: 56121, Avg. loss: 0.063077\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 5.48, NNZs: 22, Bias: -1.116648, T: 60438, Avg. loss: 0.061114\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 5.75, NNZs: 22, Bias: -1.114181, T: 64755, Avg. loss: 0.059338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 5.98, NNZs: 22, Bias: -1.060117, T: 69072, Avg. loss: 0.057557\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 6.25, NNZs: 22, Bias: -1.102205, T: 73389, Avg. loss: 0.056025\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 6.48, NNZs: 22, Bias: -1.095582, T: 77706, Avg. loss: 0.054611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 6.71, NNZs: 22, Bias: -1.069998, T: 82023, Avg. loss: 0.053247\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 6.93, NNZs: 22, Bias: -1.078709, T: 86340, Avg. loss: 0.051931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 7.14, NNZs: 22, Bias: -1.053389, T: 90657, Avg. loss: 0.050777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 7.35, NNZs: 22, Bias: -1.034369, T: 94974, Avg. loss: 0.049638\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 7.54, NNZs: 22, Bias: -1.007084, T: 99291, Avg. loss: 0.048538\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7.73, NNZs: 22, Bias: -0.992804, T: 103608, Avg. loss: 0.047579\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7.93, NNZs: 22, Bias: -1.032731, T: 107925, Avg. loss: 0.046657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8.12, NNZs: 22, Bias: -1.022136, T: 112242, Avg. loss: 0.045805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8.29, NNZs: 22, Bias: -1.019283, T: 116559, Avg. loss: 0.044964\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8.46, NNZs: 22, Bias: -0.995134, T: 120876, Avg. loss: 0.044189\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 28 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "SGDClassifier(eta0=0.01, learning_rate='constant', loss='log', max_iter=200,\n              penalty=None, random_state=100, verbose=1)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with training set\n",
    "logreg.fit(x_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# validating or optimizing the model using validation set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "yval=logreg.predict(x_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "cnf_matrix = metrics.confusion_matrix(y_val, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy against Validation set: \n",
      " 0.9214732453092426\n",
      "Confusion Matrix: \n",
      " [[144   0   0   0   0   0   0   0   0   0]\n",
      " [  0 702   0   0   0   0   0   0   0   0]\n",
      " [  0   0  98   0   0   0   0   0   0   0]\n",
      " [  0   0   0  56   0   0   0   0   0   0]\n",
      " [  0   0   0   0 111   0   0   0   0   0]\n",
      " [  0   0   0   0   0 222   0   0   0   0]\n",
      " [  0   0   0   0   0   0  40   0   0   0]\n",
      " [  0   0   0   0   0   0   0  27   0   0]\n",
      " [  0   0   0   0   0   0   0   0  11   0]\n",
      " [  0   0   0   0   0   0   0   0   0  28]]\n",
      "Classification Report: \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.97      0.93      0.95       150\n",
      "AdenomeraHylaedactylus       1.00      0.98      0.99       714\n",
      "    Ameeregatrivittata       0.85      0.86      0.85        97\n",
      "            HylaMinuta       0.50      0.85      0.63        33\n",
      "  HypsiboasCinerascens       0.93      0.95      0.94       108\n",
      "     HypsiboasCordobae       0.99      0.78      0.87       281\n",
      "   LeptodactylusFuscus       0.80      0.91      0.85        35\n",
      " OsteocephalusOophagus       0.00      0.00      0.00         0\n",
      "     Rhinellagranulosa       0.00      0.00      0.00         0\n",
      "           ScinaxRuber       0.75      1.00      0.86        21\n",
      "\n",
      "              accuracy                           0.92      1439\n",
      "             macro avg       0.68      0.73      0.69      1439\n",
      "          weighted avg       0.96      0.92      0.94      1439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the validation set we know that the\n",
    "print(\"Accuracy against Validation set: \\n\",metrics.accuracy_score(yval, y_val))\n",
    "print(\"Confusion Matrix: \\n\",cnf_matrix)\n",
    "print(\"Classification Report: \\n\",classification_report(yval, y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# finally, predicting the model with the test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "y_pred=logreg.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy against Test set: \n",
      " 0.920778318276581\n",
      "Confusion Matrix: \n",
      " [[144   0   0   0   0   0   0   0   0   0]\n",
      " [  0 702   0   0   0   0   0   0   0   0]\n",
      " [  0   0  98   0   0   0   0   0   0   0]\n",
      " [  0   0   0  56   0   0   0   0   0   0]\n",
      " [  0   0   0   0 111   0   0   0   0   0]\n",
      " [  0   0   0   0   0 222   0   0   0   0]\n",
      " [  0   0   0   0   0   0  40   0   0   0]\n",
      " [  0   0   0   0   0   0   0  27   0   0]\n",
      " [  0   0   0   0   0   0   0   0  11   0]\n",
      " [  0   0   0   0   0   0   0   0   0  28]]\n",
      "Classification Report: \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        AdenomeraAndre       0.92      0.91      0.92       149\n",
      "AdenomeraHylaedactylus       1.00      0.97      0.98       714\n",
      "    Ameeregatrivittata       0.93      0.87      0.90       114\n",
      "            HylaMinuta       0.44      0.93      0.60        27\n",
      "  HypsiboasCinerascens       0.96      0.92      0.94        93\n",
      "     HypsiboasCordobae       0.98      0.82      0.89       276\n",
      "   LeptodactylusFuscus       0.85      0.94      0.89        49\n",
      " OsteocephalusOophagus       0.00      0.00      0.00         0\n",
      "     Rhinellagranulosa       0.00      0.00      0.00         0\n",
      "           ScinaxRuber       0.62      0.88      0.73        17\n",
      "\n",
      "              accuracy                           0.92      1439\n",
      "             macro avg       0.67      0.72      0.69      1439\n",
      "          weighted avg       0.96      0.92      0.94      1439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy against Test set: \\n\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"Confusion Matrix: \\n\",cnf_matrix)\n",
    "print(\"Classification Report: \\n\",classification_report(y_pred, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Iteration, Train:  0.714616631920315 , Validation:  0.7407922168172342\n",
      "2 Iteration, Train:  0.8010192263145703 , Validation:  0.8207088255733148\n",
      "3 Iteration, Train:  0.8149177669678017 , Validation:  0.8353022932592078\n",
      "4 Iteration, Train:  0.8209404679175353 , Validation:  0.8346073662265462\n",
      "5 Iteration, Train:  0.8290479499652537 , Validation:  0.8457261987491314\n",
      "6 Iteration, Train:  0.8498957609451008 , Validation:  0.8610145934676859\n",
      "7 Iteration, Train:  0.858003242992819 , Validation:  0.8693537178596248\n",
      "8 Iteration, Train:  0.8654157980078758 , Validation:  0.8763029881862404\n",
      "9 Iteration, Train:  0.8723650683344916 , Validation:  0.8832522585128562\n",
      "10 Iteration, Train:  0.8793143386611072 , Validation:  0.891591382904795\n",
      "11 Iteration, Train:  0.8853370396108409 , Validation:  0.8971507991660875\n",
      "12 Iteration, Train:  0.8897382441510308 , Validation:  0.8971507991660875\n",
      "13 Iteration, Train:  0.8969191568218671 , Validation:  0.906184850590688\n",
      "14 Iteration, Train:  0.8957609451007644 , Validation:  0.9047949965253649\n",
      "15 Iteration, Train:  0.8983090108871902 , Validation:  0.9041000694927033\n",
      "16 Iteration, Train:  0.901783646050498 , Validation:  0.9117442668519805\n",
      "17 Iteration, Train:  0.9031735001158212 , Validation:  0.9117442668519805\n",
      "18 Iteration, Train:  0.9045633541811443 , Validation:  0.9117442668519805\n",
      "19 Iteration, Train:  0.9073430623117906 , Validation:  0.9166087560806115\n",
      "20 Iteration, Train:  0.9098911280982164 , Validation:  0.9173036831132731\n",
      "21 Iteration, Train:  0.9126708362288626 , Validation:  0.9186935371785963\n",
      "22 Iteration, Train:  0.9105860551308779 , Validation:  0.9200833912439194\n",
      "23 Iteration, Train:  0.9140606902941858 , Validation:  0.920778318276581\n",
      "24 Iteration, Train:  0.9112809821635395 , Validation:  0.9193884642112579\n",
      "25 Iteration, Train:  0.9166087560806115 , Validation:  0.9228630993745657\n",
      "26 Iteration, Train:  0.9119759091962011 , Validation:  0.920778318276581\n",
      "27 Iteration, Train:  0.9096594857539958 , Validation:  0.9193884642112579\n",
      "28 Iteration, Train:  0.9135974056057448 , Validation:  0.9221681723419041\n",
      "29 Iteration, Train:  0.9126708362288626 , Validation:  0.920778318276581\n",
      "30 Iteration, Train:  0.9161454713921705 , Validation:  0.9221681723419041\n",
      "31 Iteration, Train:  0.9166087560806115 , Validation:  0.9193884642112579\n",
      "32 Iteration, Train:  0.9149872596710679 , Validation:  0.9228630993745657\n",
      "33 Iteration, Train:  0.9119759091962011 , Validation:  0.9235580264072273\n",
      "34 Iteration, Train:  0.9147556173268473 , Validation:  0.9214732453092426\n",
      "35 Iteration, Train:  0.9135974056057448 , Validation:  0.920778318276581\n",
      "36 Iteration, Train:  0.9145239749826268 , Validation:  0.9221681723419041\n",
      "37 Iteration, Train:  0.9122075515404215 , Validation:  0.9228630993745657\n",
      "38 Iteration, Train:  0.9142923326384063 , Validation:  0.9221681723419041\n",
      "39 Iteration, Train:  0.9131341209173037 , Validation:  0.9214732453092426\n",
      "40 Iteration, Train:  0.9147556173268473 , Validation:  0.9228630993745657\n",
      "41 Iteration, Train:  0.9149872596710679 , Validation:  0.9228630993745657\n",
      "42 Iteration, Train:  0.9145239749826268 , Validation:  0.9221681723419041\n",
      "43 Iteration, Train:  0.9126708362288626 , Validation:  0.920778318276581\n",
      "44 Iteration, Train:  0.9145239749826268 , Validation:  0.9235580264072273\n",
      "45 Iteration, Train:  0.9147556173268473 , Validation:  0.9214732453092426\n",
      "46 Iteration, Train:  0.9140606902941858 , Validation:  0.9228630993745657\n",
      "47 Iteration, Train:  0.9154505443595089 , Validation:  0.9242529534398888\n",
      "48 Iteration, Train:  0.9145239749826268 , Validation:  0.9235580264072273\n",
      "49 Iteration, Train:  0.9145239749826268 , Validation:  0.9235580264072273\n",
      "50 Iteration, Train:  0.9170720407690526 , Validation:  0.9270326615705351\n",
      "51 Iteration, Train:  0.9145239749826268 , Validation:  0.9228630993745657\n",
      "52 Iteration, Train:  0.9145239749826268 , Validation:  0.9249478804725504\n",
      "53 Iteration, Train:  0.9133657632615242 , Validation:  0.9228630993745657\n",
      "54 Iteration, Train:  0.9124391938846421 , Validation:  0.9193884642112579\n",
      "55 Iteration, Train:  0.9131341209173037 , Validation:  0.9221681723419041\n",
      "56 Iteration, Train:  0.9149872596710679 , Validation:  0.9235580264072273\n",
      "57 Iteration, Train:  0.9131341209173037 , Validation:  0.9214732453092426\n",
      "58 Iteration, Train:  0.9124391938846421 , Validation:  0.920778318276581\n",
      "59 Iteration, Train:  0.9142923326384063 , Validation:  0.9228630993745657\n",
      "60 Iteration, Train:  0.9142923326384063 , Validation:  0.9249478804725504\n",
      "61 Iteration, Train:  0.9126708362288626 , Validation:  0.9221681723419041\n",
      "62 Iteration, Train:  0.9138290479499652 , Validation:  0.9221681723419041\n",
      "63 Iteration, Train:  0.9154505443595089 , Validation:  0.9242529534398888\n",
      "64 Iteration, Train:  0.9131341209173037 , Validation:  0.9228630993745657\n",
      "65 Iteration, Train:  0.9126708362288626 , Validation:  0.920778318276581\n",
      "66 Iteration, Train:  0.9142923326384063 , Validation:  0.9221681723419041\n",
      "67 Iteration, Train:  0.9133657632615242 , Validation:  0.9228630993745657\n",
      "68 Iteration, Train:  0.9182302524901552 , Validation:  0.9270326615705351\n",
      "69 Iteration, Train:  0.9124391938846421 , Validation:  0.9214732453092426\n",
      "70 Iteration, Train:  0.9142923326384063 , Validation:  0.925642807505212\n",
      "71 Iteration, Train:  0.9133657632615242 , Validation:  0.9214732453092426\n",
      "72 Iteration, Train:  0.9126708362288626 , Validation:  0.9200833912439194\n",
      "73 Iteration, Train:  0.9135974056057448 , Validation:  0.9235580264072273\n",
      "74 Iteration, Train:  0.9142923326384063 , Validation:  0.9228630993745657\n",
      "75 Iteration, Train:  0.9133657632615242 , Validation:  0.9214732453092426\n",
      "76 Iteration, Train:  0.9138290479499652 , Validation:  0.9221681723419041\n",
      "77 Iteration, Train:  0.9154505443595089 , Validation:  0.9242529534398888\n",
      "78 Iteration, Train:  0.9119759091962011 , Validation:  0.9200833912439194\n",
      "79 Iteration, Train:  0.9133657632615242 , Validation:  0.920778318276581\n",
      "80 Iteration, Train:  0.9140606902941858 , Validation:  0.9221681723419041\n",
      "81 Iteration, Train:  0.9138290479499652 , Validation:  0.9221681723419041\n",
      "82 Iteration, Train:  0.9129024785730832 , Validation:  0.920778318276581\n",
      "83 Iteration, Train:  0.9117442668519805 , Validation:  0.920778318276581\n",
      "84 Iteration, Train:  0.9161454713921705 , Validation:  0.9263377345378735\n",
      "85 Iteration, Train:  0.9135974056057448 , Validation:  0.9214732453092426\n",
      "86 Iteration, Train:  0.9142923326384063 , Validation:  0.9221681723419041\n",
      "87 Iteration, Train:  0.9126708362288626 , Validation:  0.9235580264072273\n",
      "88 Iteration, Train:  0.9133657632615242 , Validation:  0.9221681723419041\n",
      "89 Iteration, Train:  0.9154505443595089 , Validation:  0.9228630993745657\n",
      "90 Iteration, Train:  0.9122075515404215 , Validation:  0.920778318276581\n",
      "91 Iteration, Train:  0.9147556173268473 , Validation:  0.9249478804725504\n",
      "92 Iteration, Train:  0.9152189020152884 , Validation:  0.9242529534398888\n",
      "93 Iteration, Train:  0.9135974056057448 , Validation:  0.9221681723419041\n",
      "94 Iteration, Train:  0.9149872596710679 , Validation:  0.9242529534398888\n",
      "95 Iteration, Train:  0.9154505443595089 , Validation:  0.9228630993745657\n",
      "96 Iteration, Train:  0.9135974056057448 , Validation:  0.9200833912439194\n",
      "97 Iteration, Train:  0.9133657632615242 , Validation:  0.9221681723419041\n",
      "98 Iteration, Train:  0.9156821867037295 , Validation:  0.9235580264072273\n",
      "99 Iteration, Train:  0.9122075515404215 , Validation:  0.9193884642112579\n",
      "100 Iteration, Train:  0.9152189020152884 , Validation:  0.9235580264072273\n",
      "101 Iteration, Train:  0.9122075515404215 , Validation:  0.9200833912439194\n",
      "102 Iteration, Train:  0.9154505443595089 , Validation:  0.925642807505212\n",
      "103 Iteration, Train:  0.9142923326384063 , Validation:  0.9221681723419041\n",
      "104 Iteration, Train:  0.9135974056057448 , Validation:  0.9214732453092426\n",
      "105 Iteration, Train:  0.9138290479499652 , Validation:  0.9200833912439194\n",
      "106 Iteration, Train:  0.9147556173268473 , Validation:  0.9235580264072273\n",
      "107 Iteration, Train:  0.9138290479499652 , Validation:  0.9214732453092426\n",
      "108 Iteration, Train:  0.9147556173268473 , Validation:  0.9228630993745657\n",
      "109 Iteration, Train:  0.9131341209173037 , Validation:  0.920778318276581\n",
      "110 Iteration, Train:  0.9140606902941858 , Validation:  0.9235580264072273\n",
      "111 Iteration, Train:  0.9119759091962011 , Validation:  0.9228630993745657\n",
      "112 Iteration, Train:  0.9135974056057448 , Validation:  0.9214732453092426\n",
      "113 Iteration, Train:  0.9131341209173037 , Validation:  0.920778318276581\n",
      "114 Iteration, Train:  0.9129024785730832 , Validation:  0.920778318276581\n",
      "115 Iteration, Train:  0.9122075515404215 , Validation:  0.9214732453092426\n",
      "116 Iteration, Train:  0.9117442668519805 , Validation:  0.9200833912439194\n",
      "117 Iteration, Train:  0.9135974056057448 , Validation:  0.9242529534398888\n",
      "118 Iteration, Train:  0.9131341209173037 , Validation:  0.9221681723419041\n",
      "119 Iteration, Train:  0.9154505443595089 , Validation:  0.9235580264072273\n",
      "120 Iteration, Train:  0.9147556173268473 , Validation:  0.9242529534398888\n",
      "121 Iteration, Train:  0.911049339819319 , Validation:  0.9214732453092426\n",
      "122 Iteration, Train:  0.9142923326384063 , Validation:  0.9221681723419041\n",
      "123 Iteration, Train:  0.9140606902941858 , Validation:  0.9228630993745657\n",
      "124 Iteration, Train:  0.9138290479499652 , Validation:  0.9228630993745657\n",
      "125 Iteration, Train:  0.9138290479499652 , Validation:  0.9228630993745657\n",
      "126 Iteration, Train:  0.9149872596710679 , Validation:  0.9249478804725504\n",
      "127 Iteration, Train:  0.9140606902941858 , Validation:  0.9228630993745657\n",
      "128 Iteration, Train:  0.9149872596710679 , Validation:  0.9221681723419041\n",
      "129 Iteration, Train:  0.9124391938846421 , Validation:  0.920778318276581\n",
      "130 Iteration, Train:  0.9126708362288626 , Validation:  0.9221681723419041\n",
      "131 Iteration, Train:  0.9124391938846421 , Validation:  0.9214732453092426\n",
      "132 Iteration, Train:  0.9124391938846421 , Validation:  0.9221681723419041\n",
      "133 Iteration, Train:  0.9129024785730832 , Validation:  0.9200833912439194\n",
      "134 Iteration, Train:  0.9142923326384063 , Validation:  0.920778318276581\n",
      "135 Iteration, Train:  0.9145239749826268 , Validation:  0.9235580264072273\n",
      "136 Iteration, Train:  0.9145239749826268 , Validation:  0.9228630993745657\n",
      "137 Iteration, Train:  0.9149872596710679 , Validation:  0.9249478804725504\n",
      "138 Iteration, Train:  0.9142923326384063 , Validation:  0.9228630993745657\n",
      "139 Iteration, Train:  0.9152189020152884 , Validation:  0.9242529534398888\n",
      "140 Iteration, Train:  0.9131341209173037 , Validation:  0.9221681723419041\n",
      "141 Iteration, Train:  0.9133657632615242 , Validation:  0.920778318276581\n",
      "142 Iteration, Train:  0.9129024785730832 , Validation:  0.920778318276581\n",
      "143 Iteration, Train:  0.9135974056057448 , Validation:  0.9221681723419041\n",
      "144 Iteration, Train:  0.9142923326384063 , Validation:  0.920778318276581\n",
      "145 Iteration, Train:  0.9152189020152884 , Validation:  0.9235580264072273\n",
      "146 Iteration, Train:  0.9133657632615242 , Validation:  0.9214732453092426\n",
      "147 Iteration, Train:  0.9145239749826268 , Validation:  0.9228630993745657\n",
      "148 Iteration, Train:  0.9131341209173037 , Validation:  0.9228630993745657\n",
      "149 Iteration, Train:  0.9112809821635395 , Validation:  0.9193884642112579\n",
      "150 Iteration, Train:  0.9129024785730832 , Validation:  0.9214732453092426\n",
      "151 Iteration, Train:  0.9138290479499652 , Validation:  0.9228630993745657\n",
      "152 Iteration, Train:  0.9140606902941858 , Validation:  0.9214732453092426\n",
      "153 Iteration, Train:  0.9131341209173037 , Validation:  0.9214732453092426\n",
      "154 Iteration, Train:  0.9126708362288626 , Validation:  0.9221681723419041\n",
      "155 Iteration, Train:  0.9119759091962011 , Validation:  0.920778318276581\n",
      "156 Iteration, Train:  0.9145239749826268 , Validation:  0.9235580264072273\n",
      "157 Iteration, Train:  0.9131341209173037 , Validation:  0.9214732453092426\n",
      "158 Iteration, Train:  0.9135974056057448 , Validation:  0.9214732453092426\n",
      "159 Iteration, Train:  0.9138290479499652 , Validation:  0.9221681723419041\n",
      "160 Iteration, Train:  0.9140606902941858 , Validation:  0.9228630993745657\n",
      "161 Iteration, Train:  0.9133657632615242 , Validation:  0.9214732453092426\n",
      "162 Iteration, Train:  0.9138290479499652 , Validation:  0.9228630993745657\n",
      "163 Iteration, Train:  0.9129024785730832 , Validation:  0.9235580264072273\n",
      "164 Iteration, Train:  0.9152189020152884 , Validation:  0.9228630993745657\n",
      "165 Iteration, Train:  0.9108176974750984 , Validation:  0.9221681723419041\n",
      "166 Iteration, Train:  0.9147556173268473 , Validation:  0.9228630993745657\n",
      "167 Iteration, Train:  0.9140606902941858 , Validation:  0.9221681723419041\n",
      "168 Iteration, Train:  0.9124391938846421 , Validation:  0.920778318276581\n",
      "169 Iteration, Train:  0.9126708362288626 , Validation:  0.9214732453092426\n",
      "170 Iteration, Train:  0.9142923326384063 , Validation:  0.9235580264072273\n",
      "171 Iteration, Train:  0.9119759091962011 , Validation:  0.920778318276581\n",
      "172 Iteration, Train:  0.9129024785730832 , Validation:  0.9235580264072273\n",
      "173 Iteration, Train:  0.9142923326384063 , Validation:  0.9200833912439194\n",
      "174 Iteration, Train:  0.9159138290479499 , Validation:  0.9249478804725504\n",
      "175 Iteration, Train:  0.9156821867037295 , Validation:  0.9221681723419041\n",
      "176 Iteration, Train:  0.9135974056057448 , Validation:  0.9228630993745657\n",
      "177 Iteration, Train:  0.9124391938846421 , Validation:  0.9214732453092426\n",
      "178 Iteration, Train:  0.9147556173268473 , Validation:  0.9235580264072273\n",
      "179 Iteration, Train:  0.9129024785730832 , Validation:  0.920778318276581\n",
      "180 Iteration, Train:  0.9131341209173037 , Validation:  0.920778318276581\n",
      "181 Iteration, Train:  0.9140606902941858 , Validation:  0.9228630993745657\n",
      "182 Iteration, Train:  0.9133657632615242 , Validation:  0.9235580264072273\n",
      "183 Iteration, Train:  0.9133657632615242 , Validation:  0.9235580264072273\n",
      "184 Iteration, Train:  0.9126708362288626 , Validation:  0.9193884642112579\n",
      "185 Iteration, Train:  0.9149872596710679 , Validation:  0.9221681723419041\n",
      "186 Iteration, Train:  0.9154505443595089 , Validation:  0.9221681723419041\n",
      "187 Iteration, Train:  0.9124391938846421 , Validation:  0.9200833912439194\n",
      "188 Iteration, Train:  0.916377113736391 , Validation:  0.9228630993745657\n",
      "189 Iteration, Train:  0.9147556173268473 , Validation:  0.9228630993745657\n",
      "190 Iteration, Train:  0.9149872596710679 , Validation:  0.9228630993745657\n",
      "191 Iteration, Train:  0.9140606902941858 , Validation:  0.9221681723419041\n",
      "192 Iteration, Train:  0.9131341209173037 , Validation:  0.9214732453092426\n",
      "193 Iteration, Train:  0.9126708362288626 , Validation:  0.9214732453092426\n",
      "194 Iteration, Train:  0.9131341209173037 , Validation:  0.9214732453092426\n",
      "195 Iteration, Train:  0.9133657632615242 , Validation:  0.9214732453092426\n",
      "196 Iteration, Train:  0.9117442668519805 , Validation:  0.9214732453092426\n",
      "197 Iteration, Train:  0.9135974056057448 , Validation:  0.9228630993745657\n",
      "198 Iteration, Train:  0.9138290479499652 , Validation:  0.9214732453092426\n",
      "199 Iteration, Train:  0.9135974056057448 , Validation:  0.9228630993745657\n"
     ]
    }
   ],
   "source": [
    "# algorithm to compare scores in each iteration\n",
    "losses = []\n",
    "iteration = []\n",
    "tr = []\n",
    "val = []\n",
    "for i in range(1, 200):\n",
    "    logreg = SGDClassifier(loss='log', eta0=0.01, learning_rate='constant', penalty=None, max_iter=i)\n",
    "    logreg.fit(x_train, y_train)\n",
    "\n",
    "    score_tr=logreg.score(x_train,y_train)\n",
    "    score_val=logreg.score(x_val,y_val)\n",
    "\n",
    "    iteration.append(i)\n",
    "    tr.append(score_tr)\n",
    "    val.append(score_val)\n",
    "\n",
    "    print(i,\"Iteration,\", \"Train: \", score_tr, \", Validation: \", score_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy score against train set:  0.9182302524901552\n",
      "Max accuracy score against validation set:  0.9270326615705351\n"
     ]
    }
   ],
   "source": [
    "print(\"Max accuracy score against train set: \", max(tr))\n",
    "print(\"Max accuracy score against validation set: \",max(val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph comparison of the accuracy between training & validation set\n",
    "plt.plot(tr,color=\"red\",label=\"Train\")\n",
    "plt.plot(val,color=\"blue\",label=\"Validation\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}